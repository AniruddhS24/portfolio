---
const systemPrompt = `You are Aniruddh Sriram, the owner of this portfolio website. You're chatting with visitors who want to get to know you better.

# Identity

You are a software engineer and NLP researcher passionate about building intelligent systems. You studied math and computer science in the Turing Scholars program at UT Austin, where you fell in love with the intersection of statistics, machine learning, and practical software engineering.

You've worked in fintech at Bloomberg and quant finance at The Voleon Group, where you got to tackle challenging problems at the intersection of data, algorithms, and real-world systems.

These days, you're particularly interested in natural language processing, especially building resilient fact-checking systems and improving how AI systems handle complex reasoning. You love backend development and you are most proficient in Python, C++, and Golang.

# Personality & Style

- Be friendly, approachable, and conversational - like you're chatting over coffee
- IMPORTANT:Keep responses concise (1 sentence)
- DO NOT hallucinate or say anything that is not provided to you in the Identity section
- Use "I" - you ARE Aniruddh, not an AI assistant

# Example Responses

- "Hello, I'm Aniruddh. Nice to meet you! Feel free to explore the projects page to see some of my work."
- "I became interested in natural language processing during my time at UT Austin"
- "I have worked on building fact-checking systems"
- "I love backend development and I am most proficient in Python, C++, and Golang"
`;
---

<div class="chat-container">
  <div class="terminal-input-container mb-4">
    <div class="flex items-center gap-2 font-mono text-base">
      <span class="zag-muted zag-transition select-none">&gt;</span>
      <input
        type="text"
        id="chat-input"
        placeholder="say hi"
        class="flex-1 bg-transparent zag-text zag-transition outline-none border-none"
        autocomplete="off"
      />
    </div>
    <div class="flex justify-between items-center mt-2">
      <p id="status" class="text-xs zag-muted zag-transition font-mono"></p>
      <p class="text-xs zag-muted zag-transition font-mono">Llama 3.2 3B Instruct</p>
    </div>
  </div>

  <div id="response-container" class="hidden">
    <div class="zag-border-t pt-4">
      <div id="response-content" class="response-text max-w-none font-mono text-sm leading-relaxed">
      </div>
    </div>
  </div>
</div>

<!-- Pass system prompt to client-side JS -->
<script id="system-prompt" type="text/plain" set:html={systemPrompt} />

<script>
  import { CreateMLCEngine } from "@mlc-ai/web-llm";
  import { marked } from "marked";

  // Configure marked for safe rendering
  marked.setOptions({
    breaks: true,
    gfm: true,
  });

  // Load system prompt from embedded script
  const systemPrompt = document.getElementById("system-prompt")!.textContent || "";

  const MODEL_ID = "Llama-3.2-3B-Instruct-q4f16_1-MLC";
  
  let engine: any = null;
  let isLoading = false;
  let enginePromise: Promise<any> | null = null;

  const input = document.getElementById("chat-input") as HTMLInputElement;
  const status = document.getElementById("status") as HTMLSpanElement;
  const responseContainer = document.getElementById("response-container") as HTMLDivElement;
  const responseContent = document.getElementById("response-content") as HTMLDivElement;

  const initProgressCallback = (progress: { text: string; progress: number }) => {
    status.textContent = progress.text;
  };

  async function initEngine() {
    if (engine) return engine;
    if (enginePromise) return enginePromise;
    
    isLoading = true;
    status.textContent = "Loading model...";
    
    enginePromise = CreateMLCEngine(MODEL_ID, {
      initProgressCallback,
    });
    
    try {
      engine = await enginePromise;
      status.textContent = "Ready";
      setTimeout(() => {
        status.textContent = "";
      }, 2000);
    } catch (error) {
      console.error("Failed to load model:", error);
      status.textContent = "Failed to load model";
      enginePromise = null;
      throw error;
    } finally {
      isLoading = false;
    }
    
    return engine;
  }

  // Start loading model in the background immediately
  // Model files are cached in IndexedDB, so navigating away and back is fine
  initEngine().catch(() => {
    // Silently handle - user will see error when they try to use it
  });

  async function handleSubmit() {
    const query = input.value.trim();
    if (!query) return;

    // Show response container and clear previous response
    responseContainer.classList.remove("hidden");
    responseContent.innerHTML = "";
    
    // Disable input while processing
    input.disabled = true;
    status.textContent = "Thinking...";

    try {
      // Initialize engine if not already done
      const eng = await initEngine();

      const messages = [
        { role: "system", content: systemPrompt },
        { role: "user", content: query },
      ];

      // Stream the response
      const chunks = await eng.chat.completions.create({
        messages,
        temperature: 0.8,
        stream: true,
        stream_options: { include_usage: true },
      });

      let reply = "";
      for await (const chunk of chunks) {
        const delta = chunk.choices[0]?.delta?.content || "";
        reply += delta;
        // Render markdown
        const htmlContent = marked.parse(reply) as string;
        responseContent.innerHTML = htmlContent;
      }

      status.textContent = "";
    } catch (error) {
      console.error("Error:", error);
      responseContent.innerHTML = `<p class="error-text">Error: ${error instanceof Error ? error.message : "Something went wrong"}</p>`;
      status.textContent = "";
    } finally {
      input.disabled = false;
      input.focus();
    }
  }

  // Handle Enter key
  input.addEventListener("keydown", (e) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  });

  // Focus input on load
  input.focus();
</script>

<style>
  .chat-container {
    width: 100%;
  }

  .terminal-input-container {
    border-bottom: 1px solid var(--color-zag-dark-muted);
    padding-bottom: 0.5rem;
  }
  :global(.dark) .terminal-input-container {
    border-bottom-color: var(--color-zag-light-muted);
  }

  #chat-input {
    caret-color: currentColor;
  }

  #chat-input::placeholder {
    opacity: 0.4;
    font-style: italic;
  }

  /* Response text - respects light/dark mode */
  .response-text {
    color: var(--color-zag-dark);
  }
  :global(.dark) .response-text {
    color: var(--color-zag-light);
  }

  .error-text {
    color: #ef4444;
  }

  /* Markdown content styling */
  #response-content :global(p) {
    margin-bottom: 1em;
  }

  #response-content :global(p:last-child) {
    margin-bottom: 0;
  }

  #response-content :global(code) {
    padding: 0.2em 0.4em;
    border-radius: 3px;
    font-size: 0.9em;
    background-color: var(--color-zag-dark);
    color: var(--color-zag-light);
  }
  :global(.dark) #response-content :global(code) {
    background-color: var(--color-zag-light);
    color: var(--color-zag-dark);
  }

  #response-content :global(pre) {
    padding: 1em;
    border-radius: 6px;
    overflow-x: auto;
    margin: 1em 0;
    background-color: var(--color-zag-dark);
    color: var(--color-zag-light);
  }
  :global(.dark) #response-content :global(pre) {
    background-color: rgba(255, 255, 255, 0.1);
    color: var(--color-zag-light);
  }

  #response-content :global(pre code) {
    padding: 0;
    background: none;
    color: inherit;
  }

  #response-content :global(ul),
  #response-content :global(ol) {
    margin: 1em 0;
    padding-left: 1.5em;
  }

  #response-content :global(li) {
    margin: 0.5em 0;
  }

  #response-content :global(h1),
  #response-content :global(h2),
  #response-content :global(h3),
  #response-content :global(h4) {
    margin-top: 1.5em;
    margin-bottom: 0.5em;
    font-weight: 600;
  }

  #response-content :global(blockquote) {
    border-left: 3px solid currentColor;
    padding-left: 1em;
    margin: 1em 0;
    opacity: 0.8;
  }

  #response-content :global(a) {
    text-decoration: underline;
    color: var(--color-zag-accent-dark);
  }
  :global(.dark) #response-content :global(a) {
    color: var(--color-zag-accent-light);
  }

  #response-content :global(a:hover) {
    text-decoration: none;
  }

  #response-content :global(strong) {
    font-weight: 600;
  }
</style>
