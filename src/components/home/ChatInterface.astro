---
import { getCollection } from "astro:content";
import { getConfigurationCollection } from "../../lib/utils";

const { data: config } = await getConfigurationCollection();

// Fetch all content at build time
const projects = (await getCollection("project")).sort(
  (a, b) => b.data.timestamp.valueOf() - a.data.timestamp.valueOf()
);
const blogs = (await getCollection("blog")).sort(
  (a, b) => b.data.timestamp.valueOf() - a.data.timestamp.valueOf()
);
const research = (await getCollection("research")).sort(
  (a, b) => b.data.timestamp.valueOf() - a.data.timestamp.valueOf()
);

// Build content index with IDs
const contentIndex = {
  projects: projects.map((p, i) => ({
    id: `P${i + 1}`,
    title: p.data.title,
    description: p.data.description,
    tags: p.data.tags || [],
    url: `/projects/${p.data.slug}`,
    githubUrl: p.data.githubUrl,
  })),
  blogs: blogs.map((b, i) => ({
    id: `B${i + 1}`,
    title: b.data.title,
    description: b.data.description,
    tags: b.data.tags || [],
    url: `/blog/${b.data.slug}`,
  })),
  research: research.map((r, i) => ({
    id: `R${i + 1}`,
    title: r.data.title,
    authors: r.data.authors,
    venue: r.data.venue,
    paperUrl: r.data.paperUrl,
    codeUrl: r.data.codeUrl,
  })),
};

// Build the system prompt with clearer formatting
const projectsList = contentIndex.projects
  .map(p => `- ID: ${p.id}
  Name: "${p.title}"
  Description: ${p.description}
  Technologies: ${p.tags.join(", ") || "not specified"}`)
  .join("\n\n");

const blogsList = contentIndex.blogs
  .map(b => `- ID: ${b.id}
  Title: "${b.title}"
  Description: ${b.description}`)
  .join("\n\n");

const researchList = contentIndex.research
  .map(r => `- ID: ${r.id}
  Paper: "${r.title}"
  Venue: ${r.venue}`)
  .join("\n\n");

const systemPrompt = `You are the owner of this website, a software engineer and NLP researcher. When you answer, you are speaking AS this person in the first person ("I", "my"), not as an AI assistant.

# Identity

I am a software engineer and NLP researcher.

I have worked in fintech (Bloomberg) and quant finance (The Voleon Group).

I studied math and computer science in the Turing Scholars program at UT Austin.

I love math, backend software development, and doing research.

My main interests are statistics and machine learning, especially building resilient fact-checking systems.

# Style

Tone: friendly, thoughtful, and technical when appropriate.

You can mention my background briefly when relevant (e.g., "In my work at Bloomberg…" or "During my time in the Turing Scholars program at UT Austin…").

Do NOT say "As an AI" or "As a language model". You are always speaking as the human owner of the site.

# Task Overview

You will be given some context about your personal projects, research papers, and blog posts. You must answer the user's query using this context.

Each project, paper, blog post has a short ID (for example: P1, P2, R1, B3)

If you reference any of these, you MUST attach its ID using double square brackets in your response. This will get replaced with a hyperlink to the project, paper, or blog post.

# Instructions

- Only use provided information

- If the user asks about anything that is not covered, say you don't know based on the information here. Example:
  "I don't have that information in my project and paper list."

- Never invent projects, papers, or posts

- Do NOT create new projects, papers, jobs, or achievements.

- Do NOT guess missing details.

- If something is not listed, say you don't know.

## Linking syntax for items (important)

Every time you mention a project, paper, or blog post, you MUST attach its ID using double square brackets.

The format is EXACTLY:

Projects: [[P1]], [[P2]], ...

Research papers: [[R1]], [[R2]], ...

Blog posts: [[B1]], [[B2]], ...

Put the ID right after the title or phrase. Examples:

"You can read more in my project on resilient fact-checking systems [[P1]]."

"This is based on my paper about claim verification [[R2]]."

"I wrote about this in a blog post on evaluation pitfalls [[B3]]."

**Never change this format**: No extra spaces inside the brackets. No other link formats (no Markdown links, no HTML, no parentheses-only like (P1)).

## How to answer questions

Speak in the first person as the website owner ("I", "my").

Be CONCISE: 1-4 sentences unless the user asks for more detail.

If the user asks about:

a specific project/paper/blog by name → answer using its description and link it with its ID, like [[P1]].

a topic (e.g. "fact-checking", "construction costs") → use the most relevant items from the lists and link them.

If the user asks something that spans multiple items, you can mention several, each with its ID:

"I explored this both in my project on fact-checking [[P1]] and my later paper on robustness [[R3]]."

If information is missing or unclear

If you can't find anything relevant in the lists, say so clearly.

Example: "I don't see any projects or papers about that in my current list."
`;

const assistantContext = `Here is the website content - you must use EXACTLY this to answer user questions:

PERSONAL PROJECTS:
${projectsList}

RESEARCH PAPERS:
${researchList}

BLOG POSTS:
${blogsList}`;
---

<div class="chat-container">
  <div class="terminal-input-container mb-4">
    <div class="flex items-center gap-2 font-mono text-base">
      <span class="zag-muted zag-transition select-none">&gt;</span>
      <input
        type="text"
        id="chat-input"
        placeholder="say hi"
        class="flex-1 bg-transparent zag-text zag-transition outline-none border-none"
        autocomplete="off"
      />
    </div>
    <div class="flex justify-between items-center mt-2">
      <p id="status" class="text-xs zag-muted zag-transition font-mono"></p>
      <p class="text-xs zag-muted zag-transition font-mono">Llama 3.1 8B Instruct</p>
    </div>
  </div>

  <div id="response-container" class="hidden">
    <div class="zag-border-t pt-4">
      <div id="response-content" class="response-text max-w-none font-mono text-sm leading-relaxed">
      </div>
    </div>
  </div>
</div>

<!-- Pass data to client-side JS -->
<script id="content-data" type="application/json" set:html={JSON.stringify(contentIndex)} />
<script id="system-prompt" type="text/plain" set:html={systemPrompt} />
<script id="assistant-context" type="text/plain" set:html={assistantContext} />

<script>
  import { CreateMLCEngine } from "@mlc-ai/web-llm";
  import { marked } from "marked";

  // Configure marked for safe rendering
  marked.setOptions({
    breaks: true,
    gfm: true,
  });

  // Load content data and system prompt from embedded scripts
  const contentData = JSON.parse(document.getElementById("content-data")!.textContent || "{}");
  const systemPrompt = document.getElementById("system-prompt")!.textContent || "";
  const assistantContext = document.getElementById("assistant-context")!.textContent || "";

  // Build a lookup map for quick ID -> content resolution
  type ContentItem = { id: string; title: string; url?: string; paperUrl?: string };
  const contentMap = new Map<string, ContentItem>();
  
  contentData.projects?.forEach((p: ContentItem) => contentMap.set(p.id, p));
  contentData.blogs?.forEach((b: ContentItem) => contentMap.set(b.id, b));
  contentData.research?.forEach((r: ContentItem) => contentMap.set(r.id, r));

  // Post-process response to convert [[ID]] to actual links
  function processPortfolioLinks(html: string): string {
    // Match [[P1]], [[B2]], [[R3]] etc.
    return html.replace(/\[\[([A-Z]\d+)\]\]/g, (match, id) => {
      const item = contentMap.get(id);
      if (!item) return match;
      
      // For research papers, use paperUrl; for others use internal url
      const url = item.url || item.paperUrl || "#";
      const isExternal = url.startsWith("http");
      const target = isExternal ? ' target="_blank" rel="noopener noreferrer"' : '';
      
      return `<a href="${url}"${target} class="portfolio-link">${item.title}</a>`;
    });
  }

  const MODEL_ID = "Llama-3.1-8B-Instruct-q4f16_1-MLC";
  
  let engine: any = null;
  let isLoading = false;
  let enginePromise: Promise<any> | null = null;

  const input = document.getElementById("chat-input") as HTMLInputElement;
  const status = document.getElementById("status") as HTMLSpanElement;
  const responseContainer = document.getElementById("response-container") as HTMLDivElement;
  const responseContent = document.getElementById("response-content") as HTMLDivElement;

  const initProgressCallback = (progress: { text: string; progress: number }) => {
    status.textContent = progress.text;
  };

  async function initEngine() {
    if (engine) return engine;
    if (enginePromise) return enginePromise;
    
    isLoading = true;
    status.textContent = "Loading model...";
    
    enginePromise = CreateMLCEngine(MODEL_ID, {
      initProgressCallback,
    });
    
    try {
      engine = await enginePromise;
      status.textContent = "Ready";
      setTimeout(() => {
        status.textContent = "";
      }, 2000);
    } catch (error) {
      console.error("Failed to load model:", error);
      status.textContent = "Failed to load model";
      enginePromise = null;
      throw error;
    } finally {
      isLoading = false;
    }
    
    return engine;
  }

  // Start loading model in the background immediately
  // Model files are cached in IndexedDB, so navigating away and back is fine
  initEngine().catch(() => {
    // Silently handle - user will see error when they try to use it
  });

  async function handleSubmit() {
    const query = input.value.trim();
    if (!query) return;

    // Show response container and clear previous response
    responseContainer.classList.remove("hidden");
    responseContent.innerHTML = "";
    
    // Disable input while processing
    input.disabled = true;
    status.textContent = "Thinking...";

    try {
      // Initialize engine if not already done
      const eng = await initEngine();

      const messages = [
        { role: "system", content: systemPrompt },
        { role: "assistant", content: assistantContext },
        { role: "user", content: query },
      ];

      // Stream the response
      const chunks = await eng.chat.completions.create({
        messages,
        temperature: 0.7,
        stream: true,
        stream_options: { include_usage: true },
      });

      let reply = "";
      for await (const chunk of chunks) {
        const delta = chunk.choices[0]?.delta?.content || "";
        reply += delta;
        // Render markdown and process portfolio links
        const htmlContent = marked.parse(reply) as string;
        responseContent.innerHTML = processPortfolioLinks(htmlContent);
      }

      status.textContent = "";
    } catch (error) {
      console.error("Error:", error);
      responseContent.innerHTML = `<p class="error-text">Error: ${error instanceof Error ? error.message : "Something went wrong"}</p>`;
      status.textContent = "";
    } finally {
      input.disabled = false;
      input.focus();
    }
  }

  // Handle Enter key
  input.addEventListener("keydown", (e) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  });

  // Focus input on load
  input.focus();
</script>

<style>
  .chat-container {
    width: 100%;
  }

  .terminal-input-container {
    border-bottom: 1px solid var(--color-zag-dark-muted);
    padding-bottom: 0.5rem;
  }
  :global(.dark) .terminal-input-container {
    border-bottom-color: var(--color-zag-light-muted);
  }

  #chat-input {
    caret-color: currentColor;
  }

  #chat-input::placeholder {
    opacity: 0.4;
    font-style: italic;
  }

  /* Response text - respects light/dark mode */
  .response-text {
    color: var(--color-zag-dark);
  }
  :global(.dark) .response-text {
    color: var(--color-zag-light);
  }

  .error-text {
    color: #ef4444;
  }

  /* Markdown content styling */
  #response-content :global(p) {
    margin-bottom: 1em;
  }

  #response-content :global(p:last-child) {
    margin-bottom: 0;
  }

  #response-content :global(code) {
    padding: 0.2em 0.4em;
    border-radius: 3px;
    font-size: 0.9em;
    background-color: var(--color-zag-dark);
    color: var(--color-zag-light);
  }
  :global(.dark) #response-content :global(code) {
    background-color: var(--color-zag-light);
    color: var(--color-zag-dark);
  }

  #response-content :global(pre) {
    padding: 1em;
    border-radius: 6px;
    overflow-x: auto;
    margin: 1em 0;
    background-color: var(--color-zag-dark);
    color: var(--color-zag-light);
  }
  :global(.dark) #response-content :global(pre) {
    background-color: rgba(255, 255, 255, 0.1);
    color: var(--color-zag-light);
  }

  #response-content :global(pre code) {
    padding: 0;
    background: none;
    color: inherit;
  }

  #response-content :global(ul),
  #response-content :global(ol) {
    margin: 1em 0;
    padding-left: 1.5em;
  }

  #response-content :global(li) {
    margin: 0.5em 0;
  }

  #response-content :global(h1),
  #response-content :global(h2),
  #response-content :global(h3),
  #response-content :global(h4) {
    margin-top: 1.5em;
    margin-bottom: 0.5em;
    font-weight: 600;
  }

  #response-content :global(blockquote) {
    border-left: 3px solid currentColor;
    padding-left: 1em;
    margin: 1em 0;
    opacity: 0.8;
  }

  #response-content :global(a) {
    text-decoration: underline;
    color: var(--color-zag-accent-dark);
  }
  :global(.dark) #response-content :global(a) {
    color: var(--color-zag-accent-light);
  }

  #response-content :global(a:hover) {
    text-decoration: none;
  }

  /* Portfolio link styling */
  #response-content :global(.portfolio-link) {
    font-weight: 500;
  }

  #response-content :global(strong) {
    font-weight: 600;
  }
</style>
